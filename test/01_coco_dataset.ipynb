{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_names():\n",
    "    return [\n",
    "        \"background\",\n",
    "        \"aeroplane\",\n",
    "        \"bicycle\",\n",
    "        \"bird\",\n",
    "        \"boat\",\n",
    "        \"bottle\",\n",
    "        \"bus\",\n",
    "        \"car\",\n",
    "        \"cat\",\n",
    "        \"chair\",\n",
    "        \"cow\",\n",
    "        \"diningtable\",\n",
    "        \"dog\",\n",
    "        \"horse\",\n",
    "        \"motorbike\",\n",
    "        \"person\",\n",
    "        \"potted_plant\",\n",
    "        \"sheep\",\n",
    "        \"sofa\",\n",
    "        \"train\",\n",
    "        \"tv_monitor\",\n",
    "    ]\n",
    "\n",
    "@staticmethod\n",
    "def coco_to_pascal_mapping():\n",
    "    return [\n",
    "        0,\n",
    "        5,\n",
    "        2,\n",
    "        16,\n",
    "        9,\n",
    "        44,\n",
    "        6,\n",
    "        3,\n",
    "        17,\n",
    "        62,\n",
    "        21,\n",
    "        67,\n",
    "        18,\n",
    "        19,\n",
    "        4,\n",
    "        1,\n",
    "        64,\n",
    "        20,\n",
    "        63,\n",
    "        7,\n",
    "        72,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataDir='..'\n",
    "dataDir='home/data/MS_COCO'   # this is my data path\n",
    "dataType='val2017'\n",
    "annFile='{}/annotations/instances_{}.json'.format(dataDir,dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from .. import register_dataset\n",
    "from ..dataset_base import BaseImageDataset\n",
    "from ...transforms import image_pil as T\n",
    "\n",
    "\n",
    "@register_dataset(\"coco\", \"segmentation\")\n",
    "class COCODataset(BaseImageDataset):\n",
    "    \"\"\"\n",
    "    Dataset class for the COCO dataset that maps classes to PASCAL VOC classes\n",
    "\n",
    "    Args:\n",
    "        opts: command-line arguments\n",
    "        is_training (Optional[bool]): A flag used to indicate training or validation mode. Default: True\n",
    "        is_evaluation (Optional[bool]): A flag used to indicate evaluation (or inference) mode. Default: False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        opts,\n",
    "        is_training: Optional[bool] = True,\n",
    "        is_evaluation: Optional[bool] = False,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "\n",
    "        :param opts: arguments\n",
    "        :param is_training: Training or validation mode\n",
    "        :param is_evaluation: Evaluation mode\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            opts=opts, is_training=is_training, is_evaluation=is_evaluation\n",
    "        )\n",
    "        year = 2017\n",
    "        split = \"train\" if is_training else \"val\"\n",
    "        ann_file = os.path.join(\n",
    "            self.root, \"annotations/instances_{}{}.json\".format(split, year)\n",
    "        )\n",
    "        self.img_dir = os.path.join(self.root, \"images/{}{}\".format(split, year))\n",
    "        self.split = split\n",
    "        self.coco = COCO(ann_file)\n",
    "        self.coco_mask = mask\n",
    "        self.ids = list(self.coco.imgs.keys())\n",
    "\n",
    "        self.ignore_label = 255\n",
    "        self.bgrnd_idx = 0\n",
    "\n",
    "        setattr(opts, \"model.segmentation.n_classes\", len(self.class_names()))\n",
    "\n",
    "    def __getitem__(self, batch_indexes_tup):\n",
    "        crop_size_h, crop_size_w, img_index = batch_indexes_tup\n",
    "        crop_size = (crop_size_h, crop_size_w)\n",
    "\n",
    "        if self.is_training:\n",
    "            _transform = self._training_transforms(\n",
    "                size=crop_size, ignore_idx=self.ignore_label\n",
    "            )\n",
    "        elif self.is_evaluation:\n",
    "            _transform = self._evaluation_transforms(size=crop_size)\n",
    "        else:\n",
    "            _transform = self._validation_transforms(size=crop_size)\n",
    "\n",
    "        coco = self.coco\n",
    "        img_id = self.ids[img_index]\n",
    "        img_metadata = coco.loadImgs(img_id)[0]\n",
    "        path = img_metadata[\"file_name\"]\n",
    "\n",
    "        rgb_img = self.read_image_opencv(os.path.join(self.img_dir, path))\n",
    "        cocotarget = coco.loadAnns(coco.getAnnIds(imgIds=img_id))\n",
    "\n",
    "        im_height, im_width = rgb_img.shape[:2]\n",
    "\n",
    "        mask = self._gen_seg_mask(\n",
    "            cocotarget, img_metadata[\"height\"], img_metadata[\"width\"]\n",
    "        )\n",
    "\n",
    "        data = {\"image\": rgb_img, \"mask\": None if self.is_evaluation else mask}\n",
    "\n",
    "        data = _transform(data)\n",
    "\n",
    "        if self.is_evaluation:\n",
    "            # for evaluation purposes, resize only the input and not mask\n",
    "            data[\"mask\"] = mask\n",
    "\n",
    "        output_data = {\"samples\": data[\"image\"], \"targets\": data[\"mask\"]}\n",
    "\n",
    "        if self.is_evaluation:\n",
    "            img_name = path.replace(\"jpg\", \"png\")\n",
    "            mask = output_data.pop(\"targets\")\n",
    "            output_data[\"targets\"] = {\n",
    "                \"mask\": mask,\n",
    "                \"file_name\": img_name,\n",
    "                \"im_width\": im_width,\n",
    "                \"im_height\": im_height,\n",
    "            }\n",
    "\n",
    "        return output_data\n",
    "\n",
    "    def _gen_seg_mask(self, target, h, w):\n",
    "        mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        coco_mask = self.coco_mask\n",
    "        coco_to_pascal = self.coco_to_pascal_mapping()\n",
    "        for instance in target:\n",
    "            rle = coco_mask.frPyObjects(instance[\"segmentation\"], h, w)\n",
    "            m = coco_mask.decode(rle)\n",
    "            cat = instance[\"category_id\"]\n",
    "            if cat in coco_to_pascal:\n",
    "                c = coco_to_pascal.index(cat)\n",
    "            else:\n",
    "                continue\n",
    "            if len(m.shape) < 3:\n",
    "                mask[:, :] += (mask == 0) * (m * c)\n",
    "            else:\n",
    "                mask[:, :] += (mask == 0) * (((np.sum(m, axis=2)) > 0) * c).astype(\n",
    "                    np.uint8\n",
    "                )\n",
    "        return mask\n",
    "\n",
    "    def _training_transforms(self, size: tuple, ignore_idx: Optional[int] = 255):\n",
    "        aug_list = [\n",
    "            T.RandomResize(opts=self.opts),\n",
    "            T.RandomCrop(opts=self.opts, size=size),\n",
    "            T.RandomHorizontalFlip(opts=self.opts),\n",
    "            T.ToTensor(opts=self.opts),\n",
    "        ]\n",
    "\n",
    "        return T.Compose(opts=self.opts, img_transforms=aug_list)\n",
    "\n",
    "    def _validation_transforms(self, size: tuple, *args, **kwargs):\n",
    "        aug_list = [T.Resize(opts=self.opts), T.ToTensor(opts=self.opts)]\n",
    "        return T.Compose(opts=self.opts, img_transforms=aug_list)\n",
    "\n",
    "    def _evaluation_transforms(self, size: tuple, *args, **kwargs):\n",
    "        aug_list = []\n",
    "        if getattr(self.opts, \"evaluation.segmentation.resize_input_images\", False):\n",
    "            aug_list.append(T.Resize(opts=self.opts))\n",
    "\n",
    "        aug_list.append(T.ToTensor(opts=self.opts))\n",
    "        return T.Compose(opts=self.opts, img_transforms=aug_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    @staticmethod\n",
    "    def class_names() -> List:\n",
    "        return [\n",
    "            \"background\",\n",
    "            \"aeroplane\",\n",
    "            \"bicycle\",\n",
    "            \"bird\",\n",
    "            \"boat\",\n",
    "            \"bottle\",\n",
    "            \"bus\",\n",
    "            \"car\",\n",
    "            \"cat\",\n",
    "            \"chair\",\n",
    "            \"cow\",\n",
    "            \"diningtable\",\n",
    "            \"dog\",\n",
    "            \"horse\",\n",
    "            \"motorbike\",\n",
    "            \"person\",\n",
    "            \"potted_plant\",\n",
    "            \"sheep\",\n",
    "            \"sofa\",\n",
    "            \"train\",\n",
    "            \"tv_monitor\",\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def coco_to_pascal_mapping():\n",
    "        return [\n",
    "            0,\n",
    "            5,\n",
    "            2,\n",
    "            16,\n",
    "            9,\n",
    "            44,\n",
    "            6,\n",
    "            3,\n",
    "            17,\n",
    "            62,\n",
    "            21,\n",
    "            67,\n",
    "            18,\n",
    "            19,\n",
    "            4,\n",
    "            1,\n",
    "            64,\n",
    "            20,\n",
    "            63,\n",
    "            7,\n",
    "            72,\n",
    "        ]\n",
    "\n",
    "    def __repr__(self):\n",
    "        from utils.tensor_utils import image_size_from_opts\n",
    "\n",
    "        im_h, im_w = image_size_from_opts(opts=self.opts)\n",
    "\n",
    "        if self.is_training:\n",
    "            transforms_str = self._training_transforms(size=(im_h, im_w))\n",
    "        elif self.is_evaluation:\n",
    "            transforms_str = self._evaluation_transforms(size=(im_h, im_w))\n",
    "        else:\n",
    "            transforms_str = self._validation_transforms(size=(im_h, im_w))\n",
    "\n",
    "        return \"{}(\\n\\troot={}\\n\\tis_training={}\\n\\tsamples={}\\n\\t\\n\\ttransforms={}\\n)\".format(\n",
    "            self.__class__.__name__,\n",
    "            self.root,\n",
    "            self.is_training,\n",
    "            len(self.ids),\n",
    "            transforms_str,\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "565e3544d5dbeb515a1265a05ceb357b4338ebedb8b2db99297d61f63f17eeee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
