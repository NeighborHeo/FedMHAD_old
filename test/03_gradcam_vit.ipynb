{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "import os\n",
    "import pathlib\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import torch \n",
    "import mymodels \n",
    "import mydataset \n",
    "from torch.utils.data import DataLoader\n",
    "from utils.myfed import *\n",
    "import yaml\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yamlfilepath = pathlib.Path.cwd().parent.joinpath('config.yaml')\n",
    "args = yaml.load(yamlfilepath.open('r'), Loader=yaml.FullLoader)\n",
    "args = argparse.Namespace(**args)\n",
    "args.datapath = \"~/.data\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=args.gpu\n",
    "\n",
    "# 1. data\n",
    "args.datapath = os.path.expanduser(args.datapath)\n",
    "\n",
    "if args.dataset == 'cifar10':\n",
    "    publicdata = 'cifar100'\n",
    "    args.N_class = 10\n",
    "elif args.dataset == 'cifar100':\n",
    "    publicdata = 'imagenet'\n",
    "    args.N_class = 100\n",
    "elif args.dataset == 'pascal_voc2012':\n",
    "    publicdata = 'mscoco'\n",
    "    args.N_class = 20\n",
    "\n",
    "assert args.dataset in ['cifar10', 'cifar100', 'pascal_voc2012']\n",
    "\n",
    "priv_data, _, test_dataset, public_dataset, distill_loader = mydataset.data_cifar.dirichlet_datasplit(\n",
    "    args, privtype=args.dataset, publictype=publicdata, N_parties=args.N_parties, online=not args.oneshot, public_percent=args.public_percent)\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=args.batchsize, shuffle=False, num_workers=args.num_workers, sampler=None)\n",
    "val_loader = DataLoader(\n",
    "    dataset=public_dataset, batch_size=args.batchsize, shuffle=False, num_workers=args.num_workers, sampler=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mymodels.define_model(modelname=args.model_name, num_classes=args.N_class)\n",
    "net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "loadname = os.path.join(\"/home/suncheol/code/FedTest/pytorch-model-multiclass/checkpoint/pascal_voc_vit_tiny_patch16_224_0.0001_-1_singlelabel/ckpt.pth\")\n",
    "if os.path.exists(loadname):\n",
    "    localmodels = torch.load(loadname)\n",
    "    #self.localmodels[n].load_state_dict(self.best_statdict, strict=True)\n",
    "    logging.info(f'Loading Local{n}......')\n",
    "    print('filepath : ', loadname)\n",
    "    utils.load_dict(loadname, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show 1 batch of data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels, _ = dataiter.next()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "565e3544d5dbeb515a1265a05ceb357b4338ebedb8b2db99297d61f63f17eeee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
