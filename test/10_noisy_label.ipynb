{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def add_noise(args, y_train, dict_users):\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "    gamma_s = np.random.binomial(1, args.level_n_system, args.num_users)\n",
    "    gamma_c_initial = np.random.rand(args.num_users)\n",
    "    gamma_c_initial = (1 - args.level_n_lowerb) * gamma_c_initial + args.level_n_lowerb\n",
    "    gamma_c = gamma_s * gamma_c_initial\n",
    "\n",
    "    y_train_noisy = copy.deepcopy(y_train)\n",
    "\n",
    "    real_noise_level = np.zeros(args.num_users)\n",
    "    for i in np.where(gamma_c > 0)[0]:\n",
    "        sample_idx = np.array(list(dict_users[i]))\n",
    "        prob = np.random.rand(len(sample_idx))\n",
    "        noisy_idx = np.where(prob <= gamma_c[i])[0]\n",
    "        y_train_noisy[sample_idx[noisy_idx]] = np.random.randint(0, 10, len(noisy_idx))\n",
    "        noise_ratio = np.mean(y_train[sample_idx] != y_train_noisy[sample_idx])\n",
    "        print(\"Client %d, noise level: %.4f (%.4f), real noise ratio: %.4f\" % (\n",
    "            i, gamma_c[i], gamma_c[i] * 0.9, noise_ratio))\n",
    "        real_noise_level[i] = noise_ratio\n",
    "    return (y_train_noisy, gamma_s, real_noise_level)\n",
    "\n",
    "def get_output(loader, net, args, latent=False, criterion=None):\n",
    "    net.eval()\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "            images = images.to(args.device)\n",
    "            labels = labels.to(args.device)\n",
    "            labels = labels.long()\n",
    "            if latent == False:\n",
    "                outputs = net(images)\n",
    "                outputs = F.softmax(outputs, dim=1)\n",
    "            else:\n",
    "                outputs = net(images, True)\n",
    "            loss = criterion(outputs, labels)\n",
    "            if i == 0:\n",
    "                output_whole = np.array(outputs.cpu())\n",
    "                loss_whole = np.array(loss.cpu())\n",
    "            else:\n",
    "                output_whole = np.concatenate((output_whole, outputs.cpu()), axis=0)\n",
    "                loss_whole = np.concatenate((loss_whole, loss.cpu()), axis=0)\n",
    "    if criterion is not None:\n",
    "        return output_whole, loss_whole\n",
    "    else:\n",
    "        return output_whole\n",
    "\n",
    "\n",
    "def lid_term(X, batch, k=20):\n",
    "    eps = 1e-6\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "\n",
    "    batch = np.asarray(batch, dtype=np.float32)\n",
    "    f = lambda v: - k / (np.sum(np.log(v / (v[-1]+eps)))+eps)\n",
    "    distances = cdist(X, batch)\n",
    "\n",
    "    # get the closest k neighbours\n",
    "    sort_indices = np.apply_along_axis(np.argsort, axis=1, arr=distances)[:, 1:k + 1]\n",
    "    m, n = sort_indices.shape\n",
    "    idx = np.ogrid[:m, :n]\n",
    "    idx[1] = sort_indices\n",
    "    # sorted matrix\n",
    "    distances_ = distances[tuple(idx)]\n",
    "    lids = np.apply_along_axis(f, axis=1, arr=distances_)\n",
    "    return lids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suncheol/code/FedTest/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/suncheol/code/FedTest/.venv/lib/python3.9/site-packages/torchvision/transforms/transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "\n",
    "def get_unique_classes(dataset):\n",
    "    unique_classes = set()\n",
    "    for img, mask in dataset:\n",
    "        classes = list(mask.getcolors())\n",
    "        for count, pixel_value in classes:\n",
    "            unique_classes.add(pixel_value)\n",
    "    \n",
    "    return unique_classes\n",
    "\n",
    "# 데이터셋 다운로드 및 생성\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mask_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224), interpolation=Image.NEAREST), \n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "voc_dataset = VOCSegmentation(root='~/.data', year='2012', image_set='val', download=False, transform=transforms, target_transform=mask_transforms)\n",
    "voc_dataloader = torch.utils.data.DataLoader(voc_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_img_to_target(mask, num_classes=20):\n",
    "    # get colors\n",
    "    mask = to_pil_image(mask)\n",
    "    colors = list(mask.getcolors())\n",
    "    torch_target = torch.zeros(num_classes)\n",
    "    for count, pixel_value in colors:\n",
    "        if pixel_value in [0, 255]: # 0 is background, 255 is border,\n",
    "            continue\n",
    "        torch_target[pixel_value - 1] = 1\n",
    "    return torch_target\n",
    "\n",
    "def masks_to_targets(masks, num_classes=20):\n",
    "    targets = []\n",
    "    for mask in masks:\n",
    "        targets.append(mask_img_to_target(mask, num_classes))\n",
    "    return torch.stack(targets)\n",
    "\n",
    "images, masks = iter(voc_dataloader).next()\n",
    "labels = masks_to_targets(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "noisy_labels = labels.clone()\n",
    "# for i in range(len(noisy_labels)):\n",
    "#     if random.random() < 0.5:\n",
    "#         noisy_labels[i] = torch.zeros(20)\n",
    "#     else:\n",
    "#         noisy_labels[i] = torch.ones(20)\n",
    "\n",
    "print(labels[0])\n",
    "print(noisy_labels[0])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add_noise() missing 1 required positional argument: 'dict_users'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m args \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlevel_n_system\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m0.5\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlevel_n_lowerb\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m0.1\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnum_users\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m10\u001b[39m\n\u001b[1;32m      5\u001b[0m }\n\u001b[0;32m----> 6\u001b[0m train_noisy, gamma_s, real_noise_level \u001b[39m=\u001b[39m add_noise(noisy_labels, args)\n",
      "\u001b[0;31mTypeError\u001b[0m: add_noise() missing 1 required positional argument: 'dict_users'"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"level_n_system\" : 0.5,\n",
    "    \"level_n_lowerb\" : 0.1,\n",
    "    \"num_users\" : 10\n",
    "}\n",
    "train_noisy, gamma_s, real_noise_level = add_noise(noisy_labels, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic function\n",
    "def multiclass_noisify(y, P, random_state):\n",
    "    \"\"\" Flip classes according to transition probability matrix T.\n",
    "    It expects a number between 0 and the number of classes - 1.\n",
    "    \"\"\"\n",
    "#    print (np.max(y), P.shape[0])\n",
    "    assert P.shape[0] == P.shape[1]\n",
    "    assert np.max(y) < P.shape[0]\n",
    "\n",
    "    # row stochastic matrix\n",
    "    assert_array_almost_equal(P.sum(axis=1), np.ones(P.shape[1]))\n",
    "    assert (P >= 0.0).all()\n",
    "\n",
    "    m = y.shape[0]\n",
    "    new_y = y.copy()\n",
    "    flipper = np.random.RandomState(random_state)\n",
    "\n",
    "    for idx in np.arange(m):\n",
    "        i = y[idx]\n",
    "        # draw a vector with only an 1\n",
    "        flipped = flipper.multinomial(1, P[i, :][0], 1)[0]\n",
    "        new_y[idx] = np.where(flipped == 1)[0]\n",
    "\n",
    "    return new_y\n",
    "\n",
    "\n",
    "# noisify_pairflip call the function \"multiclass_noisify\"\n",
    "def noisify_pairflip(y_train, noise, random_state=None, nb_classes=10):\n",
    "    \"\"\"mistakes:\n",
    "        flip in the pair\n",
    "    \"\"\"\n",
    "    P = np.eye(nb_classes)\n",
    "    n = noise\n",
    "\n",
    "    if n > 0.0:\n",
    "        # 0 -> 1\n",
    "        P[0, 0], P[0, 1] = 1. - n, n\n",
    "        for i in range(1, nb_classes-1):\n",
    "            P[i, i], P[i, i + 1] = 1. - n, n\n",
    "        P[nb_classes-1, nb_classes-1], P[nb_classes-1, 0] = 1. - n, n\n",
    "\n",
    "        y_train_noisy = multiclass_noisify(y_train, P=P,\n",
    "                                           random_state=random_state)\n",
    "        actual_noise = (y_train_noisy != y_train).mean()\n",
    "        assert actual_noise > 0.0\n",
    "        print('Actual noise %.2f' % actual_noise)\n",
    "        y_train = y_train_noisy\n",
    "    print (P)\n",
    "\n",
    "    return y_train, actual_noise,P\n",
    "\n",
    "def noisify_multiclass_symmetric(y_train, noise, random_state=None, nb_classes=10):\n",
    "    \"\"\"mistakes:\n",
    "        flip in the symmetric way\n",
    "    \"\"\"\n",
    "    P = np.ones((nb_classes, nb_classes))\n",
    "    n = noise\n",
    "    P = (n / (nb_classes - 1)) * P\n",
    "\n",
    "    if n > 0.0:\n",
    "        # 0 -> 1\n",
    "        P[0, 0] = 1. - n\n",
    "        for i in range(1, nb_classes-1):\n",
    "            P[i, i] = 1. - n\n",
    "        P[nb_classes-1, nb_classes-1] = 1. - n\n",
    "\n",
    "        y_train_noisy = multiclass_noisify(y_train, P=P,\n",
    "                                           random_state=random_state)\n",
    "        actual_noise = (y_train_noisy != y_train).mean()\n",
    "        assert actual_noise > 0.0\n",
    "#        print('Actual noise %.2f' % actual_noise)\n",
    "        y_train = y_train_noisy\n",
    "#    print (P)\n",
    "\n",
    "    return y_train, actual_noise,P\n",
    "\n",
    "def noisify(dataset='mnist', nb_classes=10, train_labels=None, noise_type=None, noise_rate=0, random_state=0):\n",
    "    if noise_type == 'pairflip':\n",
    "        train_noisy_labels, actual_noise_rate = noisify_pairflip(train_labels, noise_rate, random_state=0, nb_classes=nb_classes)\n",
    "    if noise_type == 'symmetric':\n",
    "        train_noisy_labels, actual_noise_rate = noisify_multiclass_symmetric(train_labels, noise_rate, random_state=0, nb_classes=nb_classes)\n",
    "    return train_noisy_labels, actual_noise_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17119ea72eb6b909bd341f4b0d7a48b5939aea29e9bd033254fedca863285074"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
