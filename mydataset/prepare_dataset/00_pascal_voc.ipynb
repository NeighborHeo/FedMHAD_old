{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if globals().get('__file__') is None:\n",
    "    __file__ = '00_pascal_voc.ipynb'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "parent_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "print('parent_dir: ', parent_dir)\n",
    "sys.path.append(parent_dir)\n",
    "# from utils.dirichlet_split import get_dirichlet_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as  models\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "# from utils import encode_labels\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_categories = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                     'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                     'cow', 'diningtable', 'dog', 'horse',\n",
    "                     'motorbike', 'person', 'pottedplant',\n",
    "                     'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "def encode_labels(target):\n",
    "    \"\"\"\n",
    "    Encode multiple labels using 1/0 encoding \n",
    "    Args:\n",
    "        target: xml tree file\n",
    "    Returns:\n",
    "        torch tensor encoding labels as 1/0 vector\n",
    "    \"\"\"\n",
    "    ls = target['annotation']['object']\n",
    "    j = []\n",
    "    if type(ls) == dict:\n",
    "        if int(ls['difficult']) == 0:\n",
    "            j.append(object_categories.index(ls['name']))\n",
    "    else:\n",
    "        for i in range(len(ls)):\n",
    "            if int(ls[i]['difficult']) == 0:\n",
    "                j.append(object_categories.index(ls[i]['name']))\n",
    "    k = np.zeros(len(object_categories))\n",
    "    k[j] = 1\n",
    "    return torch.from_numpy(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = pathlib.Path.home().joinpath('.data', 'PASCAL_VOC_2012')\n",
    "if not save_path.exists():\n",
    "    save_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize 224, 224\n",
    "transform_default = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                        transforms.ToTensor()])\n",
    "\n",
    "train_datasets = datasets.voc.VOCDetection(root='~/.data/', year='2012', image_set='train', download=False, transform = transform_default, target_transform = encode_labels)\n",
    "val_datasets = datasets.voc.VOCDetection(root='~/.data/', year='2012', image_set='val', download=False, transform = transform_default, target_transform = encode_labels)\n",
    "\n",
    "train_loader = DataLoader(train_datasets, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_datasets, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "train_images = torch.stack([image for image, _ in train_datasets]).numpy()\n",
    "train_labels = torch.stack([label for _, label in train_datasets]).numpy()\n",
    "\n",
    "val_images = torch.stack([image for image, _ in val_datasets]).numpy()\n",
    "val_labels = torch.stack([label for _, label in val_datasets]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(save_path.joinpath('train_images.npy'), train_images)\n",
    "np.save(save_path.joinpath('train_labels.npy'), train_labels)\n",
    "np.save(save_path.joinpath('val_images.npy'), val_images)\n",
    "np.save(save_path.joinpath('val_labels.npy'), val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.load(save_path.joinpath('train_images.npy'))\n",
    "train_labels = np.load(save_path.joinpath('train_labels.npy'))\n",
    "val_images = np.load(save_path.joinpath('val_images.npy'))\n",
    "val_labels = np.load(save_path.joinpath('val_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape, train_labels.shape, val_images.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, imgs, labels, transform=None):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.imgs = self._to_tensor(self.imgs)\n",
    "        self.labels = self._to_tensor(self.labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def _to_tensor(self, img):\n",
    "        if isinstance(img, np.ndarray):\n",
    "            img = torch.from_numpy(img)\n",
    "        return img\n",
    "    \n",
    "    def _to_pil_image(self, img):  \n",
    "        if not isinstance(img, Image.Image):\n",
    "            if img.shape[0] == 3:\n",
    "                # img = img.transpose(1, 2, 0)\n",
    "                img = img.permute(1, 2, 0)\n",
    "            if img.max() <= 1.0:\n",
    "                img = img*255\n",
    "            if img.dtype != np.uint8:\n",
    "                img = np.uint8(img) \n",
    "            img = Image.fromarray(img)\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            # img = self._to_tensor(img)\n",
    "            img = self._to_pil_image(img)\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "    \n",
    "    def save_npz(self, path):\n",
    "        np.savez(path, imgs=self.imgs, labels=self.labels)\n",
    "    \n",
    "    def load_npz(self, path):\n",
    "        data = np.load(path)\n",
    "        self.imgs = data['imgs']\n",
    "        self.labels = data['labels']\n",
    "\n",
    "# class CustomSegDataset(CustomDataset):\n",
    "#     def __init__(self, imgs, labels, transform=None):\n",
    "#         super().__init__(imgs, labels, transform)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         img = self.imgs[idx]\n",
    "#         label = self.labels[idx]\n",
    "        \n",
    "#         if self.transform:\n",
    "#             img = self._to_pil_image(img)\n",
    "#             img = self.transform(img)\n",
    "#         return img, label\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    # transforms.ToTensor(),\n",
    "    # transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_datasets_sub = CustomDataset(train_images, train_labels, transform=transform_train)\n",
    "train_loader_sub = DataLoader(train_datasets_sub, batch_size=16, shuffle=True, num_workers=4)\n",
    "train_images_sub = torch.stack([image for image, _ in train_datasets_sub]).numpy()\n",
    "train_labels_sub = torch.stack([label for _, label in train_datasets_sub]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_sub.shape, train_labels_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.multi_label_encoding import get_label_to_index, get_index_to_label\n",
    "\n",
    "val_indices = get_label_to_index(val_labels)\n",
    "train_indices = get_label_to_index(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.noisy_label import *\n",
    "\n",
    "adding_noise = True                                 # adding noise or not\n",
    "add_noise_type = \"symmetric\"                        # Noise Type: \"symmetric\" or \"pairflip\"\n",
    "noise_rate = 0.1                                    # Noise Rate\n",
    "\n",
    "noisy_labels = add_noisy_labels(train_labels, noise_type=add_noise_type, noise_rate=noise_rate)\n",
    "noisy_labels2 = add_noisy_labels(train_labels, noise_type=\"pairflip\", noise_rate=noise_rate)\n",
    "\n",
    "draw_confusion_matrix(train_labels, noisy_labels)\n",
    "draw_confusion_matrix(train_labels, noisy_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import utils.dirichlet_split as dirichlet\n",
    "\n",
    "def get_party_y_data(y, dict_indices_inv):\n",
    "    y = np.array([dict_indices_inv[i] for i in y])\n",
    "    return np.array(get_index_to_label(y, 20))\n",
    "\n",
    "def plot_class_distribution(y_data, object_categories, title=\"PASCAL VOC 2012\"):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    y_total = np.sum(y_data, axis=0)\n",
    "    for i in range(len(object_categories)):\n",
    "        plt.bar(object_categories[i], y_total[i])\n",
    "        plt.text(object_categories[i], y_total[i], y_total[i], ha='center', va='bottom')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Object Categories')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "    return plt\n",
    "\n",
    "# Prepare data\n",
    "unique, counts = np.unique(train_indices, return_counts=True)\n",
    "\n",
    "dict_indices = dict(zip(unique, range(len(unique))))\n",
    "dict_indices_inv = dict(zip(range(len(unique)), unique))\n",
    "X_train = train_images\n",
    "y_train = np.array([dict_indices[i] for i in train_indices])\n",
    "# y_val = np.array([dict_indices[i] for i in val_indices])\n",
    "\n",
    "N_class = len(unique)\n",
    "N_parties = 5\n",
    "alpha = 0.1\n",
    "add_noise_type = \"None\"\n",
    "noise_rate = 0\n",
    "\n",
    "dirichlet_arr = dirichlet.get_dirichlet_distribution_count(N_class, N_parties, y_train, alpha)\n",
    "dirichlet.set_random_seed(0)\n",
    "# dirichlet.plot_dirichlet_distribution(N_class, N_parties, alpha)\n",
    "# dirichlet.plot_dirichlet_distribution_count(N_class, N_parties, y_train, alpha)\n",
    "# whole_y = np.hstack((y_train, y_val))\n",
    "# dirichlet.plot_whole_y_distribution(whole_y)\n",
    "# dirichlet.plot_dirichlet_distribution_count_subplot(N_class, N_parties, y_train, alpha)\n",
    "\n",
    "split_dirichlet_data = dirichlet.get_dirichlet_split_data(X_train, y_train, N_parties, N_class, alpha)\n",
    "if add_noise_type != \"None\":\n",
    "    dirichlet_path = save_path.joinpath(f'N_clients_{N_parties}_alpha_{alpha}_noise_{add_noise_type}_{noise_rate}')\n",
    "else:\n",
    "    dirichlet_path = save_path.joinpath(f'N_clients_{N_parties}_alpha_{alpha}')\n",
    "dirichlet_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(N_parties):\n",
    "    np.save(dirichlet_path.joinpath(f'Party_{i}_X_data.npy'), split_dirichlet_data[i]['x'])\n",
    "    y_party = get_party_y_data(split_dirichlet_data[i]['y'], dict_indices_inv)\n",
    "    if add_noise_type != \"None\":\n",
    "        y_party_noisy = add_noisy_labels(y_party, noise_type=add_noise_type, noise_rate=noise_rate)\n",
    "    np.save(dirichlet_path.joinpath(f'Party_{i}_y_data.npy'), y_party)\n",
    "    if add_noise_type != \"None\":\n",
    "        np.save(dirichlet_path.joinpath(f'Party_{i}_y_data_noisy.npy'), y_party_noisy)\n",
    "    print(f'Party {i} has {len(y_party)} images')\n",
    "\n",
    "object_categories = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                     'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                     'cow', 'diningtable', 'dog', 'horse',\n",
    "                     'motorbike', 'person', 'pottedplant',\n",
    "                     'sheep', 'sofa', 'train', 'tvmonitor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for n_client in range(N_parties):\n",
    "    print(f'n_client: {n_client}')\n",
    "    if add_noise_type != \"None\":\n",
    "        dirichlet_path = save_path.joinpath(f'N_clients_{N_parties}_alpha_{alpha}_noise_{add_noise_type}_{noise_rate}')\n",
    "    else:\n",
    "        dirichlet_path = save_path.joinpath(f'N_clients_{N_parties}_alpha_{alpha}')\n",
    "    if not dirichlet_path.exists():\n",
    "        dirichlet_path.mkdir(parents=True, exist_ok=True)\n",
    "    X_train_party = np.load(dirichlet_path.joinpath(f'Party_{n_client}_X_data.npy'))\n",
    "    y_train_party = np.load(dirichlet_path.joinpath(f'Party_{n_client}_y_data.npy'))\n",
    "    plt = plot_class_distribution(y_train_party, object_categories, title=f'VOC PASCAL 2012 client {n_client} - alpha({alpha})')\n",
    "    # # Save figure\n",
    "    # plt.savefig(dirichlet_path.joinpath(f'Party_{n_client}_y_data.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.sampling import iid_sampling, non_iid_dirichlet_sampling\n",
    "\n",
    "# train_indices_sub = iid_sampling(100, 10, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = non_iid_dirichlet_sampling(train_labels, 20, 0.5, 5, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_noise(args, y_train, dict_users):\n",
    "#     np.random.seed(args.seed)\n",
    "\n",
    "#     gamma_s = np.random.binomial(1, args.level_n_system, args.num_users)\n",
    "#     gamma_c_initial = np.random.rand(args.num_users)\n",
    "#     gamma_c_initial = (1 - args.level_n_lowerb) * gamma_c_initial + args.level_n_lowerb\n",
    "#     gamma_c = gamma_s * gamma_c_initial\n",
    "\n",
    "#     y_train_noisy = copy.deepcopy(y_train)\n",
    "\n",
    "#     real_noise_level = np.zeros(args.num_users)\n",
    "#     for i in np.where(gamma_c > 0)[0]:\n",
    "#         sample_idx = np.array(list(dict_users[i]))\n",
    "#         prob = np.random.rand(len(sample_idx))\n",
    "#         noisy_idx = np.where(prob <= gamma_c[i])[0]\n",
    "#         y_train_noisy[sample_idx[noisy_idx]] = np.random.randint(0, 10, len(noisy_idx))\n",
    "#         noise_ratio = np.mean(y_train[sample_idx] != y_train_noisy[sample_idx])\n",
    "#         print(\"Client %d, noise level: %.4f (%.4f), real noise ratio: %.4f\" % (\n",
    "#             i, gamma_c[i], gamma_c[i] * 0.9, noise_ratio))\n",
    "#         real_noise_level[i] = noise_ratio\n",
    "#     return (y_train_noisy, gamma_s, real_noise_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noisy_labels(y, noise_rate):\n",
    "    y_noisy = np.copy(y)\n",
    "    for i in range(len(y)):\n",
    "        if np.random.rand() < noise_rate:\n",
    "            y_noisy[i] = np.random.randint(0, 20)\n",
    "    return y_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IID_split(X, y, n_clients):\n",
    "    n_samples = len(X)\n",
    "    n_samples_per_client = n_samples // n_clients\n",
    "    X_split = []\n",
    "    y_split = []\n",
    "    for i in range(n_clients):\n",
    "        X_split.append(X[i * n_samples_per_client: (i + 1) * n_samples_per_client])\n",
    "        y_split.append(y[i * n_samples_per_client: (i + 1) * n_samples_per_client])\n",
    "    return X_split, y_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dirichlet_split import *\n",
    "set_random_seed(0)\n",
    "\n",
    "train_images = np.load(save_path.joinpath('train_images.npy'))\n",
    "train_labels = np.load(save_path.joinpath('train_labels.npy'))\n",
    "split_dirchlet_data_dict = get_dirichlet_split_data(train_images, train_labels, N_parties=10, N_class=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# image grid\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader2)\n",
    "images, labels = dataiter.next()\n",
    " \n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_label(dataset):\n",
    "    imgs = []\n",
    "    labels = [] \n",
    "    for i, (img, label) in enumerate(dataset):\n",
    "        img, label = img.cpu().numpy(), label.cpu().numpy()\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "    imgs = np.array(imgs)\n",
    "    labels = np.array(labels)\n",
    "    return imgs, labels\n",
    "\n",
    "train_imgs, train_labels = get_img_label(train_datasets)\n",
    "val_imgs, val_labels = get_img_label(val_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASCAL VOC 2012\n",
    "path = pathlib.Path('../data/PASCAL_VOC_2012/')\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "np.save(path.joinpath('PASCAL_VOC_train_224_Img.npy'), train_imgs)\n",
    "np.save(path.joinpath('PASCAL_VOC_train_224_Label.npy'), train_labels)\n",
    "np.save(path.joinpath('PASCAL_VOC_val_224_Img.npy'), val_imgs)\n",
    "np.save(path.joinpath('PASCAL_VOC_val_224_Label.npy'), val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "import utils.utils as utils\n",
    "import utils.dirichlet_split as dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "# path = pathlib.Path('~/.data/PASCAL_VOC_2012/')\n",
    "path = pathlib.Path.home().joinpath('.data/PASCAL_VOC_2012/')\n",
    "val_imgs = np.load(path.joinpath('PASCAL_VOC_val_224_Img.npy'))\n",
    "val_labels = np.load(path.joinpath('PASCAL_VOC_val_224_Label.npy'))\n",
    "train_imgs = np.load(path.joinpath('PASCAL_VOC_train_224_Img.npy'))\n",
    "train_labels = np.load(path.joinpath('PASCAL_VOC_train_224_Label.npy'))\n",
    "val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_labels), sum(sum(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert onehotvector (labels to index for multi labels)\n",
    "'''\n",
    "[0,0,0,0,0,0] = 0\n",
    "[1,0,0,0,0,0] = 1\n",
    "[0,1,0,0,0,0] = 2\n",
    "[0,1,1,0,0,0] = 6\n",
    "\n",
    "'''\n",
    "def get_oct_num(list):\n",
    "    oct_num = 0\n",
    "    for i in range(len(list)):\n",
    "        oct_num += list[i] * 2 ** i\n",
    "    return oct_num\n",
    "\n",
    "def get_bin_num(oct, nClass):\n",
    "    bin_num = []\n",
    "    for i in range(nClass):\n",
    "        bin_num.append(oct % 2)\n",
    "        oct = oct // 2\n",
    "    return bin_num\n",
    "     \n",
    "def get_label_to_index(labels):\n",
    "    label_index = []\n",
    "    for i in range(len(labels)):\n",
    "        o = get_oct_num(labels[i])\n",
    "        label_index.append(o)\n",
    "    return label_index\n",
    "\n",
    "def get_index_to_label(label_index, nClass):\n",
    "    label_onehot = []\n",
    "    for i in range(len(label_index)):\n",
    "        label_onehot.append(get_bin_num(label_index[i], nClass))\n",
    "    return label_onehot\n",
    "\n",
    "val_indices = get_label_to_index(val_labels)\n",
    "train_indices = get_label_to_index(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total = np.sum(val_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# plot classes distritubtion\n",
    "object_categories = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                     'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                     'cow', 'diningtable', 'dog', 'horse',\n",
    "                     'motorbike', 'person', 'pottedplant',\n",
    "                     'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(len(object_categories)):\n",
    "    # not overlapped text \n",
    "    plt.bar(object_categories[i], y_total[i])\n",
    "    plt.text(object_categories[i], y_total[i], y_total[i], ha='center', va='bottom') \n",
    "plt.title(f'Pascal VOC 2012 validation set')\n",
    "plt.xlabel('Object Categories')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.savefig('Pascal VOC 2012 validation set.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(train_indices, return_counts=True)\n",
    "dict_indices = dict(zip(unique, range(len(unique))))\n",
    "dict_indices_inv = dict(zip(range(len(unique)), unique))\n",
    "X_train = train_imgs\n",
    "y_train = np.array([dict_indices[i] for i in train_indices])\n",
    "\n",
    "N_class = len(unique)\n",
    "N_parties = 5\n",
    "alpha = 1\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(img, gt, test_size=0.2, random_state=42, stratify=gt)\n",
    "\n",
    "dirchlet_arr = dirichlet.get_dirichlet_distribution_count(N_class, N_parties, y_train, alpha)\n",
    "# np.random.RandomState(1)\n",
    "dirichlet.set_random_seed(0)\n",
    "dirichlet.plot_dirichlet_distribution(N_class, N_parties, alpha)\n",
    "dirichlet.plot_dirichlet_distribution_count(N_class, N_parties, y_train, alpha)\n",
    "whole_y = np.hstack((y_train, y_test))\n",
    "dirichlet.plot_whole_y_distribution(whole_y)\n",
    "dirichlet.plot_dirichlet_distribution_count_subplot(N_class, N_parties, y_train, alpha)\n",
    "split_dirchlet_data = dirichlet.get_dirichlet_split_data(X_train, y_train, N_parties, N_class, alpha)\n",
    "y = split_dirchlet_data[0]['y']\n",
    "y = np.array([dict_indices_inv[i] for i in y])\n",
    "y = np.array(get_index_to_label(y, 20))\n",
    "y.shape\n",
    "# dirichlet_path\n",
    "dirichlet_path = pathlib.Path(f'./../data/PASCAL_VOC_2012/dirichlet/alpha_{alpha}/')\n",
    "dirichlet_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(N_parties):\n",
    "    np.save(dirichlet_path.joinpath(f'Party_{i}_X_data.npy'), split_dirchlet_data[i]['x'])\n",
    "    y = split_dirchlet_data[i]['y']\n",
    "    y = np.array([dict_indices_inv[i] for i in y])\n",
    "    y = np.array(get_index_to_label(y, 20))\n",
    "    np.save(dirichlet_path.joinpath(f'Party_{i}_y_data.npy'), y)\n",
    "    \n",
    "# plot classes distritubtion\n",
    "object_categories = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                     'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                     'cow', 'diningtable', 'dog', 'horse',\n",
    "                     'motorbike', 'person', 'pottedplant',\n",
    "                     'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "# load numpy data\n",
    "for n_client in range(N_parties):\n",
    "    print(f'n_client: {n_client}')\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    dirichlet_path = pathlib.Path(f'./../data/PASCAL_VOC_2012/dirichlet/alpha_{alpha}/')\n",
    "    X_train_0 = np.load(dirichlet_path.joinpath(f'Party_{n_client}_X_data.npy'))\n",
    "    y_train_0 = np.load(dirichlet_path.joinpath(f'Party_{n_client}_y_data.npy'))\n",
    "    y_total = np.sum(y_train_0, axis=0)\n",
    "    for i in range(len(object_categories)):\n",
    "        # not overlapped text \n",
    "        plt.bar(object_categories[i], y_total[i])\n",
    "        plt.text(object_categories[i], y_total[i], y_total[i], ha='center', va='bottom') \n",
    "    plt.title(f'PASCAL VOC 2012 (party {n_client}), alpha={alpha}')\n",
    "    plt.xlabel('Object Categories')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "\n",
    "    # save figure \n",
    "    save_path = pathlib.Path(f\"../figures/dirichlet/alpha_{alpha}/\")\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(save_path.joinpath(f'Party_{n_client}_y_data.png'))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17119ea72eb6b909bd341f4b0d7a48b5939aea29e9bd033254fedca863285074"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
