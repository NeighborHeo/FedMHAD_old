{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torchvision.models as  models\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from utils import encode_labels\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_categories = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                     'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                     'cow', 'diningtable', 'dog', 'horse',\n",
    "                     'motorbike', 'person', 'pottedplant',\n",
    "                     'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "def encode_labels(target):\n",
    "    \"\"\"\n",
    "    Encode multiple labels using 1/0 encoding \n",
    "    \n",
    "    Args:\n",
    "        target: xml tree file\n",
    "    Returns:\n",
    "        torch tensor encoding labels as 1/0 vector\n",
    "    \"\"\"\n",
    "    \n",
    "    ls = target['annotation']['object']\n",
    "  \n",
    "    j = []\n",
    "    if type(ls) == dict:\n",
    "        if int(ls['difficult']) == 0:\n",
    "            j.append(object_categories.index(ls['name']))\n",
    "  \n",
    "    else:\n",
    "        for i in range(len(ls)):\n",
    "            if int(ls[i]['difficult']) == 0:\n",
    "                j.append(object_categories.index(ls[i]['name']))\n",
    "    \n",
    "    k = np.zeros(len(object_categories))\n",
    "    k[j] = 1\n",
    "  \n",
    "    return torch.from_numpy(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize 224, 224\n",
    "transformations = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                        transforms.ToTensor()])\n",
    "train_datasets = datasets.voc.VOCDetection(root='~/.data/', year='2012', image_set='train', download=False, transform = transformations, target_transform = encode_labels)\n",
    "val_datasets = datasets.voc.VOCDetection(root='~/.data/', year='2012', image_set='val', download=False, transform = transformations, target_transform = encode_labels)\n",
    "\n",
    "train_loader = DataLoader(train_datasets, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_datasets, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_label(dataset):\n",
    "    imgs = []\n",
    "    labels = [] \n",
    "    for i, (img, label) in enumerate(dataset):\n",
    "        img, label = img.cpu().numpy(), label.cpu().numpy()\n",
    "        imgs.append(img)\n",
    "        labels.append(label)\n",
    "    imgs = np.array(imgs)\n",
    "    labels = np.array(labels)\n",
    "    return imgs, labels\n",
    "\n",
    "train_imgs, train_labels = get_img_label(train_datasets)\n",
    "val_imgs, val_labels = get_img_label(val_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASCAL VOC 2012\n",
    "path = pathlib.Path('../data/PASCAL_VOC_2012/')\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "np.save(path.joinpath('PASCAL_VOC_train_224_Img.npy'), train_imgs)\n",
    "np.save(path.joinpath('PASCAL_VOC_train_224_Label.npy'), train_labels)\n",
    "np.save(path.joinpath('PASCAL_VOC_val_224_Img.npy'), val_imgs)\n",
    "np.save(path.joinpath('PASCAL_VOC_val_224_Label.npy'), val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "import utils.utils as utils\n",
    "import utils.dirichlet_split as dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "path = pathlib.Path('../data/PASCAL_VOC_2012/')\n",
    "val_imgs = np.load(path.joinpath('PASCAL_VOC_val_224_Img.npy'))\n",
    "val_labels = np.load(path.joinpath('PASCAL_VOC_val_224_Label.npy'))\n",
    "train_imgs = np.load(path.joinpath('PASCAL_VOC_train_224_Img.npy'))\n",
    "train_labels = np.load(path.joinpath('PASCAL_VOC_train_224_Label.npy'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert onehotvector (labels to index for multi labels)\n",
    "'''\n",
    "[0,0,0,0,0,0] = 0\n",
    "[1,0,0,0,0,0] = 1\n",
    "[0,1,0,0,0,0] = 2\n",
    "[0,1,1,0,0,0] = 6\n",
    "\n",
    "'''\n",
    "def get_oct_num(list):\n",
    "    oct_num = 0\n",
    "    for i in range(len(list)):\n",
    "        oct_num += list[i] * 2 ** i\n",
    "    return oct_num\n",
    "\n",
    "def get_bin_num(oct, nClass):\n",
    "    bin_num = []\n",
    "    for i in range(nClass):\n",
    "        bin_num.append(oct % 2)\n",
    "        oct = oct // 2\n",
    "    return bin_num\n",
    "     \n",
    "def get_label_to_index(labels):\n",
    "    label_index = []\n",
    "    for i in range(len(labels)):\n",
    "        o = get_oct_num(labels[i])\n",
    "        label_index.append(o)\n",
    "    return label_index\n",
    "\n",
    "def get_index_to_label(label_index, nClass):\n",
    "    label_onehot = []\n",
    "    for i in range(len(label_index)):\n",
    "        label_onehot.append(get_bin_num(label_index[i], nClass))\n",
    "    return label_onehot\n",
    "\n",
    "val_indices = get_label_to_index(val_labels)\n",
    "train_indices = get_label_to_index(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total = np.sum(val_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot classes distritubtion\n",
    "object_categories = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                     'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                     'cow', 'diningtable', 'dog', 'horse',\n",
    "                     'motorbike', 'person', 'pottedplant',\n",
    "                     'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(len(object_categories)):\n",
    "    # not overlapped text \n",
    "    plt.bar(object_categories[i], y_total[i])\n",
    "    plt.text(object_categories[i], y_total[i], y_total[i], ha='center', va='bottom') \n",
    "plt.title(f'MSCOCO')\n",
    "plt.xlabel('Object Categories')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(train_indices, return_counts=True)\n",
    "dict_indices = dict(zip(unique, range(len(unique))))\n",
    "dict_indices_inv = dict(zip(range(len(unique)), unique))\n",
    "X_train = train_imgs\n",
    "y_train = np.array([dict_indices[i] for i in train_indices])\n",
    "\n",
    "N_class = len(unique)\n",
    "N_parties = 5\n",
    "alpha = 1\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(img, gt, test_size=0.2, random_state=42, stratify=gt)\n",
    "\n",
    "dirchlet_arr = dirichlet.get_dirichlet_distribution_count(N_class, N_parties, y_train, alpha)\n",
    "# np.random.RandomState(1)\n",
    "dirichlet.set_random_seed(0)\n",
    "dirichlet.plot_dirichlet_distribution(N_class, N_parties, alpha)\n",
    "dirichlet.plot_dirichlet_distribution_count(N_class, N_parties, y_train, alpha)\n",
    "whole_y = np.hstack((y_train, y_test))\n",
    "dirichlet.plot_whole_y_distribution(whole_y)\n",
    "dirichlet.plot_dirichlet_distribution_count_subplot(N_class, N_parties, y_train, alpha)\n",
    "split_dirchlet_data = dirichlet.get_dirichlet_split_data(X_train, y_train, N_parties, N_class, alpha)\n",
    "y = split_dirchlet_data[0]['y']\n",
    "y = np.array([dict_indices_inv[i] for i in y])\n",
    "y = np.array(get_index_to_label(y, 20))\n",
    "y.shape\n",
    "# dirichlet_path\n",
    "dirichlet_path = pathlib.Path(f'./../data/PASCAL_VOC_2012/dirichlet/alpha_{alpha}/')\n",
    "dirichlet_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(N_parties):\n",
    "    np.save(dirichlet_path.joinpath(f'Party_{i}_X_data.npy'), split_dirchlet_data[i]['x'])\n",
    "    y = split_dirchlet_data[i]['y']\n",
    "    y = np.array([dict_indices_inv[i] for i in y])\n",
    "    y = np.array(get_index_to_label(y, 20))\n",
    "    np.save(dirichlet_path.joinpath(f'Party_{i}_y_data.npy'), y)\n",
    "    \n",
    "# plot classes distritubtion\n",
    "object_categories = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                     'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                     'cow', 'diningtable', 'dog', 'horse',\n",
    "                     'motorbike', 'person', 'pottedplant',\n",
    "                     'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "# load numpy data\n",
    "for n_client in range(N_parties):\n",
    "    print(f'n_client: {n_client}')\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    dirichlet_path = pathlib.Path(f'./../data/PASCAL_VOC_2012/dirichlet/alpha_{alpha}/')\n",
    "    X_train_0 = np.load(dirichlet_path.joinpath(f'Party_{n_client}_X_data.npy'))\n",
    "    y_train_0 = np.load(dirichlet_path.joinpath(f'Party_{n_client}_y_data.npy'))\n",
    "    y_total = np.sum(y_train_0, axis=0)\n",
    "    for i in range(len(object_categories)):\n",
    "        # not overlapped text \n",
    "        plt.bar(object_categories[i], y_total[i])\n",
    "        plt.text(object_categories[i], y_total[i], y_total[i], ha='center', va='bottom') \n",
    "    plt.title(f'PASCAL VOC 2012 (party {n_client}), alpha={alpha}')\n",
    "    plt.xlabel('Object Categories')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.legend()\n",
    "\n",
    "    # save figure \n",
    "    save_path = pathlib.Path(f\"../figures/dirichlet/alpha_{alpha}/\")\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(save_path.joinpath(f'Party_{n_client}_y_data.png'))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
